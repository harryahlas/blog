ds
}
set.seed(6)
id_train <- sample(nrow(df), size = 10)# 0.7*nrow(df))
ds_train <- data_generator(
df[id_train,],
batch_size = 1,#32,
window_size_ms = 30,
window_stride_ms = 10
)
ds_validation <- data_generator(
df[-id_train,],
batch_size =1,# 32,
shuffle = FALSE,
window_size_ms = 30,
window_stride_ms = 10
)
sess <- tf$Session()
batch <- next_batch(ds_train)
str(sess$run(batch))
# Load libraries
require(rnn)
require(tuneR)
require(tidyr)
require(dplyr)
require(reshape2)
require(ggplot2)
diwave <- readWave("C:\\Development\\Kemper Wav analysis\\Audio\\DI_00.wav")
distwave <- readWave("C:\\Development\\Kemper Wav analysis\\Audio\\KranK D w_ Mesa_289.wav")
diwave@left <- c(rep(diwave@left,25))
distwave@left <- c(rep(distwave@left,25))
number_of_seconds <- ceiling(length(diwave@left)/44100) - 1
for (i in (1:number_of_seconds)) {
start_num <- (44100 * (i-1)) + 1
end_num   <- start_num + 44100
wv <- Wave(left = diwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 10000)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\di", i, ".wav"),
extensible = TRUE)
wv <- Wave(left = distwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 10000)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\dist", i, ".wav"),
extensible = TRUE)
}
for (i in (1:number_of_seconds)) {
start_num <- (44100 * (i-1)) + 1
end_num   <- start_num + 44100
wv <- Wave(left = diwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 11000)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\di", i, ".wav"),
extensible = TRUE)
wv <- Wave(left = distwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 11000)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\dist", i, ".wav"),
extensible = TRUE)
}
for (i in (1:number_of_seconds)) {
start_num <- (44100 * (i-1)) + 1
end_num   <- start_num + 44100
wv <- Wave(left = diwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 10580)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\di", i, ".wav"),
extensible = TRUE)
wv <- Wave(left = distwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 10580)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\dist", i, ".wav"),
extensible = TRUE)
}
for (i in (1:number_of_seconds)) {
start_num <- (44100 * (i-1)) + 1
end_num   <- start_num + 44100
wv <- Wave(left = diwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 11400)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\di", i, ".wav"),
extensible = TRUE)
wv <- Wave(left = distwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 11400)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\dist", i, ".wav"),
extensible = TRUE)
}
for (i in (1:number_of_seconds)) {
start_num <- (44100 * (i-1)) + 1
end_num   <- start_num + 44100
wv <- Wave(left = diwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 11200)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\di", i, ".wav"),
extensible = TRUE)
wv <- Wave(left = distwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 11200)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\dist", i, ".wav"),
extensible = TRUE)
}
for (i in (1:number_of_seconds)) {
start_num <- (44100 * (i-1)) + 1
end_num   <- start_num + 44100
wv <- Wave(left = diwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 11100)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\di", i, ".wav"),
extensible = TRUE)
wv <- Wave(left = distwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 11100)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\dist", i, ".wav"),
extensible = TRUE)
}
for (i in (1:number_of_seconds)) {
start_num <- (44100 * (i-1)) + 1
end_num   <- start_num + 44100
wv <- Wave(left = diwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 11000)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\di", i, ".wav"),
extensible = TRUE)
wv <- Wave(left = distwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 11000)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\dist", i, ".wav"),
extensible = TRUE)
}
for (i in (1:number_of_seconds)) {
start_num <- (44100 * (i-1)) + 1
end_num   <- start_num + 44100
wv <- Wave(left = diwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 10800)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\di", i, ".wav"),
extensible = TRUE)
wv <- Wave(left = distwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 10800)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\dist", i, ".wav"),
extensible = TRUE)
}
for (i in (1:number_of_seconds)) {
start_num <- (44100 * (i-1)) + 1
end_num   <- start_num + 44100
wv <- Wave(left = diwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 10700)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\di", i, ".wav"),
extensible = TRUE)
wv <- Wave(left = distwave@left[start_num:end_num], bit = 24)
wv <- downsample(wv, 10700)
#wv <- tuneR::normalize(wv, "8")
writeWave(wv,
paste0("C:\\Development\\R code\\Keras tests\\audio classification\\waves\\dist", i, ".wav"),
extensible = TRUE)
}
knitr::opts_chunk$set(echo = TRUE)
setwd("C:\\Development\\R code\\Keras tests\\audio classification")
#
# dir.create("data")
#
# download.file(
#   url = "http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz",
#   destfile = "data/speech_commands_v0.01.tar.gz"
# )
#
# untar("data/speech_commands_v0.01.tar.gz", exdir = "data/speech_commands_v0.01")
library(stringr)
library(dplyr)
files <- fs::dir_ls(
path = "waves/",
recursive = TRUE,
glob = "*.wav"
)
files <- files[!str_detect(files, "background_noise")]
df <- data_frame(
fname = files,
class = if_else(str_detect(fname, "dist"), "dist", "di"),
class_id = class %>% as.factor() %>% as.integer() - 1L
)
# save(df, file = "data/dfguitars.rda")
# load("data/dfguitars.rda")
# library(keras)
# library(tensorflow)
# load("data/df.rda")
library(tfdatasets)
ds <- tensor_slices_dataset(df)
window_size_ms <- 30
window_stride_ms <- 10
window_size <- as.integer(16000*window_size_ms/1000)
stride <- as.integer(16000*window_stride_ms/1000)
fft_size <- as.integer(2^trunc(log(window_size, 2)) + 1)
n_chunks <- length(seq(window_size/2, 16000 - window_size/2, stride))
audio_ops <- tf$contrib$framework$python$ops$audio_ops
ds <- ds %>%
dataset_map(function(obs) {
# a good way to debug when building tfdatsets pipelines is to use a print
# statement like this:
# print(str(obs))
# decoding wav files
audio_binary <- tf$read_file(tf$reshape(obs$fname, shape = list()))
wav <- audio_ops$decode_wav(audio_binary, desired_channels = 1)
# create the spectrogram
spectrogram <- audio_ops$audio_spectrogram(
wav$audio,
window_size = window_size,
stride = stride,
magnitude_squared = TRUE
)
# normalization
spectrogram <- tf$log(tf$abs(spectrogram) + 0.01)
# moving channels to last dim
spectrogram <- tf$transpose(spectrogram, perm = c(1L, 2L, 0L))
# transform the class_id into a one-hot encoded vector
response <- tf$one_hot(obs$class_id, 30L)
list(spectrogram, response)
})
ds <- ds %>%
dataset_shuffle(buffer_size = 100) %>%
dataset_repeat() %>%
dataset_padded_batch(
batch_size = 1,#32
padded_shapes = list(
shape(n_chunks, fft_size, NULL),
shape(NULL)
)
)
data_generator <- function(df, batch_size, shuffle = TRUE,
window_size_ms = 30, window_stride_ms = 10) {
window_size <- as.integer(16000*window_size_ms/1000)
stride <- as.integer(16000*window_stride_ms/1000)
fft_size <- as.integer(2^trunc(log(window_size, 2)) + 1)
n_chunks <- length(seq(window_size/2, 16000 - window_size/2, stride))
ds <- tensor_slices_dataset(df)
if (shuffle)
ds <- ds %>% dataset_shuffle(buffer_size = 100)
ds <- ds %>%
dataset_map(function(obs) {
# decoding wav files
audio_binary <- tf$read_file(tf$reshape(obs$fname, shape = list()))
wav <- audio_ops$decode_wav(audio_binary, desired_channels = 1)
# create the spectrogram
spectrogram <- audio_ops$audio_spectrogram(
wav$audio,
window_size = window_size,
stride = stride,
magnitude_squared = TRUE
)
spectrogram <- tf$log(tf$abs(spectrogram) + 0.01)
spectrogram <- tf$transpose(spectrogram, perm = c(1L, 2L, 0L))
# transform the class_id into a one-hot encoded vector
response <- tf$one_hot(obs$class_id, 29L)
list(spectrogram, response)
}) %>%
dataset_repeat()
ds <- ds %>%
dataset_padded_batch(batch_size, list(shape(n_chunks, fft_size, NULL), shape(NULL)))
ds
}
set.seed(6)
id_train <- sample(nrow(df), size = 10)# 0.7*nrow(df))
ds_train <- data_generator(
df[id_train,],
batch_size = 1,#32,
window_size_ms = 30,
window_stride_ms = 10
)
ds_validation <- data_generator(
df[-id_train,],
batch_size =1,# 32,
shuffle = FALSE,
window_size_ms = 30,
window_stride_ms = 10
)
sess <- tf$Session()
batch <- next_batch(ds_train)
str(sess$run(batch))
knitr::opts_chunk$set(echo = TRUE)
setwd("C:\\Development\\R code\\Keras tests\\audio classification")
#
# dir.create("data")
#
# download.file(
#   url = "http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz",
#   destfile = "data/speech_commands_v0.01.tar.gz"
# )
#
# untar("data/speech_commands_v0.01.tar.gz", exdir = "data/speech_commands_v0.01")
library(stringr)
library(dplyr)
files <- fs::dir_ls(
path = "waves/",
recursive = TRUE,
glob = "*.wav"
)
files <- files[!str_detect(files, "background_noise")]
df <- data_frame(
fname = files,
class = if_else(str_detect(fname, "dist"), "dist", "di"),
class_id = class %>% as.factor() %>% as.integer() - 1L
)
# save(df, file = "data/dfguitars.rda")
# load("data/dfguitars.rda")
# library(keras)
# library(tensorflow)
# load("data/df.rda")
library(tfdatasets)
ds <- tensor_slices_dataset(df)
window_size_ms <- 30
window_stride_ms <- 10
window_size <- as.integer(16000*window_size_ms/1000)
stride <- as.integer(16000*window_stride_ms/1000)
fft_size <- as.integer(2^trunc(log(window_size, 2)) + 1)
n_chunks <- length(seq(window_size/2, 16000 - window_size/2, stride))
audio_ops <- tf$contrib$framework$python$ops$audio_ops
ds <- ds %>%
dataset_map(function(obs) {
# a good way to debug when building tfdatsets pipelines is to use a print
# statement like this:
# print(str(obs))
# decoding wav files
audio_binary <- tf$read_file(tf$reshape(obs$fname, shape = list()))
wav <- audio_ops$decode_wav(audio_binary, desired_channels = 1)
# create the spectrogram
spectrogram <- audio_ops$audio_spectrogram(
wav$audio,
window_size = window_size,
stride = stride,
magnitude_squared = TRUE
)
# normalization
spectrogram <- tf$log(tf$abs(spectrogram) + 0.01)
# moving channels to last dim
spectrogram <- tf$transpose(spectrogram, perm = c(1L, 2L, 0L))
# transform the class_id into a one-hot encoded vector
response <- tf$one_hot(obs$class_id, 30L)
list(spectrogram, response)
})
ds <- ds %>%
dataset_shuffle(buffer_size = 100) %>%
dataset_repeat() %>%
dataset_padded_batch(
batch_size = 1,#32
padded_shapes = list(
shape(n_chunks, fft_size, NULL),
shape(NULL)
)
)
data_generator <- function(df, batch_size, shuffle = TRUE,
window_size_ms = 30, window_stride_ms = 10) {
window_size <- as.integer(16000*window_size_ms/1000)
stride <- as.integer(16000*window_stride_ms/1000)
fft_size <- as.integer(2^trunc(log(window_size, 2)) + 1)
n_chunks <- length(seq(window_size/2, 16000 - window_size/2, stride))
ds <- tensor_slices_dataset(df)
if (shuffle)
ds <- ds %>% dataset_shuffle(buffer_size = 100)
ds <- ds %>%
dataset_map(function(obs) {
# decoding wav files
audio_binary <- tf$read_file(tf$reshape(obs$fname, shape = list()))
wav <- audio_ops$decode_wav(audio_binary, desired_channels = 1)
# create the spectrogram
spectrogram <- audio_ops$audio_spectrogram(
wav$audio,
window_size = window_size,
stride = stride,
magnitude_squared = TRUE
)
spectrogram <- tf$log(tf$abs(spectrogram) + 0.01)
spectrogram <- tf$transpose(spectrogram, perm = c(1L, 2L, 0L))
# transform the class_id into a one-hot encoded vector
response <- tf$one_hot(obs$class_id, 29L)
list(spectrogram, response)
}) %>%
dataset_repeat()
ds <- ds %>%
dataset_padded_batch(batch_size, list(shape(n_chunks, fft_size, NULL), shape(NULL)))
ds
}
set.seed(6)
id_train <- sample(nrow(df), size = 10)# 0.7*nrow(df))
ds_train <- data_generator(
df[id_train,],
batch_size = 1,#32,
window_size_ms = 30,
window_stride_ms = 10
)
ds_validation <- data_generator(
df[-id_train,],
batch_size =1,# 32,
shuffle = FALSE,
window_size_ms = 30,
window_stride_ms = 10
)
sess <- tf$Session()
batch <- next_batch(ds_train)
str(sess$run(batch))
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
readClipboard()
devtools::create("C:\\Development\\github\\test")
# Create data
library(RMariaDB)
library(tidyverse)
# Connect to database stored on localhost
HRSAMPLE <- dbConnect(RMariaDB::MariaDB(), user='newuser', password='newuser', dbname='hrsample', host='localhost')
# Retrieve tables
employeeinfo_table <- dbGetQuery(HRSAMPLE, "SELECT *  FROM employeeinfo")
deskhistory_table  <- dbGetQuery(HRSAMPLE, "SELECT *  FROM deskhistory")
# Put your data files into the data-raw folder
save(employeeinfo_table, file = "data-raw/employeeinfo_table.rda")
# Put your data files into the data-raw folder
save(employeeinfo_table, file = "C:\\Development\\github\\test\\data-raw/employeeinfo_table.rda")
save(deskhistory_table,  file = "C:\\Development\\github\\testdata-raw/deskhistory_table.rda")
save(deskhistory_table,  file = "C:\\Development\\github\\test\\data-raw/deskhistory_table.rda")
library(test)
library(test)
employeeinfo_table
remove.packages("test")
library(test)
devtools::install_github("harryahlas/test")
?install_github
devtools::install_github("harryahlas/test")
employeeinfo_table
library(test)
employeeinfo_table
install.packages("hrsample")
devtools::create("C:\\Development\\github\\hrsample")
devtools::install_github("smithjd/sqlpetr")
library(sqlpetr)
sp_docker_remove_container("cattle")
sp_check_that_docker_is_up()
sp_make_simple_pg("cattle")
sp_check_that_docker_is_up()
sp_docker_containers_tibble()
con <- sp_get_postgres_connection(
host = "localhost",
port = 5439,
user = "postgres",
password = "postgres",
dbname = "postgres",
seconds_to_test = 30,
connection_tab = TRUE
)
remotes::install_github("smithjd/sqlpetr", ref = "wait-for-postgresql", force = TRUE)
library(sqlpetr)
sp_docker_remove_container("cattle")
sp_check_that_docker_is_up()
sp_make_simple_pg("cattle")
sp_docker_remove_container("cattle")
sp_check_that_docker_is_up()
sp_make_simple_pg("cattle")
library(RCurl)
setwd("C:\\Development\\github\\blog")
blog_files_all <- list.files(getwd(),
#pattern=(".html"),
full.names=F,
recursive = TRUE)
# do not change this file or image files
blog_files <- blog_files_all[blog_files_all != "scripts/updateURLs.R"]
blog_files <- blog_files[grepl(blog_files,pattern = "/images/") != TRUE]
blog_files <- blog_files[grepl(blog_files,pattern = "jpg|png|gif") != TRUE]
pw <- "3mypj5xh"
for (blog_file in blog_files_all) {
print(blog_file)
ftpUpload(blog_file,
paste0("sftp://edemise:",pw,"@boron.he.net/home/edemise/public_html/harry.ahlas.com/",
blog_file),
.opts = list(ftp.create.missing.dirs=TRUE)
)
}
# do not change this file or image files
blog_files <- blog_files_all[blog_files_all != "scripts/updateURLs.R"]
blog_files <- blog_files[grepl(blog_files,pattern = "/images/") != TRUE]
blog_files <- blog_files[grepl(blog_files,pattern = "jpg|png|gif") != TRUE]
blog_files_all <- list.files(getwd(),
#pattern=(".html"),
full.names=F,
recursive = TRUE)
# do not change this file or image files
blog_files <- blog_files_all[blog_files_all != "scripts/updateURLs.R"]
blog_files <- blog_files[grepl(blog_files,pattern = "/images/") != TRUE]
blog_files <- blog_files[grepl(blog_files,pattern = "jpg|png|gif") != TRUE]
for (blog_file in blog_files_all) {
print(blog_file)
ftpUpload(blog_file,
paste0("sftp://edemise:",pw,"@boron.he.net/home/edemise/public_html/harry.ahlas.com/",
blog_file),
.opts = list(ftp.create.missing.dirs=TRUE)
)
}
